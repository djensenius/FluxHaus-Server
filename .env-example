# Server Configuration
PORT=8888

# Authentication
BASIC_AUTH_PASSWORD=  # Legacy admin fallback during OIDC transition
RHIZOME_PASSWORD=
DEMO_PASSWORD=

# OIDC (Authentik)
OIDC_ISSUER_URL=https://auth.example.com/application/o/fluxhaus/
OIDC_CLIENT_ID=
OIDC_CLIENT_SECRET=
OIDC_REDIRECT_URI=https://haus.fluxhaus.io/auth/callback

# Session
SESSION_SECRET=change-me-to-a-random-string

# PostgreSQL
POSTGRES_URL=postgresql://fluxhaus:password@localhost:5432/fluxhaus

# InfluxDB
INFLUXDB_URL=http://localhost:8086
INFLUXDB_TOKEN=
INFLUXDB_ORG=fluxhaus
INFLUXDB_BUCKET=fluxhaus

# CORS
CORS_ORIGINS=http://localhost:8080,https://haus.fluxhaus.io

# Logging
LOG_LEVEL=info

# Robot Configuration
# Connection Type: 'direct' or 'homeassistant'
ROBOT_CONNECTION_TYPE=direct

# Home Assistant Configuration (Required if ROBOT_CONNECTION_TYPE=homeassistant)
# To get a token:
# 1. Log in to Home Assistant
# 2. Click your profile (bottom left)
# 3. Scroll to "Long-Lived Access Tokens"
# 4. Create a new token
HOMEASSISTANT_URL=http://homeassistant.local:8123
HOMEASSISTANT_TOKEN=
BROOMBOT_ENTITY_ID=vacuum.broombot
BROOMBOT_BATTERY_ENTITY_ID=sensor.broombot_battery
MOPBOT_ENTITY_ID=vacuum.mopbot
MOPBOT_BATTERY_ENTITY_ID=sensor.mopbot_battery

# Direct Robot Connection Configuration (Required if ROBOT_CONNECTION_TYPE=direct)
broombotModel=
broombotBlid=
broombotPassword=
broombotIp=
mopbotModel=
mopbotBlid=
mopbotPassword=
mopbotIp=

# Car Configuration (via Home Assistant Kia integration)
# Entity prefix is the name of your vehicle in Home Assistant (e.g., "kia_ev6")
CAR_ENTITY_PREFIX=kia

# Camera
CAMERA_URL=

# Miele Integration
mieleClientId=
mieleSecretId=
mieleAppliances=

# Bosch / Home Connect Integration
boschClientId=
boschSecretId=
boschAppliance=

# HomeKit Favorites
favouriteHomeKit=

# Modern Dog Integration
MODERN_DOG_URL=
MODERN_DOG_TOKEN=
MODERN_DOG_COOKIE=

# AI / Voice Configuration
# AI_PROVIDER: LLM backend for command processing.
#   Supported: openai (default), anthropic, copilot/github-copilot, zai/z.ai, azure-openai
#   Best for main model handling: openai (GPT-4o), anthropic (Claude), or copilot (GitHub Copilot)
AI_PROVIDER=openai
AI_MODEL=

# OpenAI (AI_PROVIDER=openai, STT_PROVIDER=openai, TTS_PROVIDER=openai)
# A single key covers LLM, Whisper STT, and TTS.
OPENAI_API_KEY=

# Azure OpenAI (AI_PROVIDER=azure-openai or STT_PROVIDER=azure-openai)
# Create an Azure OpenAI resource in the Azure portal, then deploy models under it.
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_ENDPOINT=https://<resource-name>.openai.azure.com
AZURE_OPENAI_DEPLOYMENT=gpt-4o
AZURE_OPENAI_STT_DEPLOYMENT=whisper
AZURE_OPENAI_API_VERSION=2024-12-01-preview

# STT (Speech-to-Text): transcribes voice input before sending to LLM.
#   Supported: openai (default), azure, azure-openai, google
#   Best for V2T: openai (Whisper) or azure-openai (Whisper via Azure)
STT_PROVIDER=openai
STT_MODEL=whisper-1
# Azure STT (STT_PROVIDER=azure)
AZURE_SPEECH_KEY=
AZURE_SPEECH_REGION=eastus
AZURE_SPEECH_LANGUAGE=en-US
# Google STT (STT_PROVIDER=google)
GOOGLE_API_KEY=
GOOGLE_STT_LANGUAGE=en-US
GOOGLE_STT_ENCODING=WEBM_OPUS
GOOGLE_STT_SAMPLE_RATE=16000

# TTS (Text-to-Speech): synthesizes LLM response back to audio.
#   Supported: openai (default), azure, google, elevenlabs
#   Best for voice generation: openai (tts-1 / tts-1-hd) or elevenlabs (premium)
TTS_PROVIDER=openai
TTS_MODEL=tts-1
# TTS_VOICE: alloy (default) | ash | coral | echo | fable | onyx | nova | sage | shimmer
TTS_VOICE=alloy
# Azure TTS (TTS_PROVIDER=azure) — shares AZURE_SPEECH_KEY and AZURE_SPEECH_REGION above
AZURE_TTS_VOICE=en-US-JennyNeural
# Google TTS (TTS_PROVIDER=google) — shares GOOGLE_API_KEY above
GOOGLE_TTS_VOICE=en-US-Neural2-F
# ElevenLabs TTS (TTS_PROVIDER=elevenlabs)
ELEVENLABS_API_KEY=
ELEVENLABS_VOICE_ID=21m00Tcm4TlvDq8ikWAM
ELEVENLABS_MODEL=eleven_monolingual_v1
