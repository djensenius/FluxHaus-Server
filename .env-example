# Server Configuration
PORT=8888

# Authentication
BASIC_AUTH_PASSWORD=  # Legacy admin fallback during OIDC transition
RHIZOME_PASSWORD=
DEMO_PASSWORD=

# OIDC (Authentik)
OIDC_ISSUER_URL=https://auth.example.com/application/o/fluxhaus/
OIDC_CLIENT_ID=
OIDC_CLIENT_SECRET=
OIDC_REDIRECT_URI=https://haus.fluxhaus.io/auth/callback

# Session
SESSION_SECRET=change-me-to-a-random-string

# PostgreSQL
POSTGRES_URL=postgresql://fluxhaus:password@localhost:5432/fluxhaus

# InfluxDB
INFLUXDB_URL=http://localhost:8086
INFLUXDB_TOKEN=
INFLUXDB_ORG=fluxhaus
INFLUXDB_BUCKET=fluxhaus

# CORS
CORS_ORIGINS=http://localhost:8080,https://haus.fluxhaus.io

# Logging
LOG_LEVEL=info

# Robot Configuration
# Connection Type: 'direct' or 'homeassistant'
ROBOT_CONNECTION_TYPE=direct

# Home Assistant Configuration (Required if ROBOT_CONNECTION_TYPE=homeassistant)
# To get a token:
# 1. Log in to Home Assistant
# 2. Click your profile (bottom left)
# 3. Scroll to "Long-Lived Access Tokens"
# 4. Create a new token
HOMEASSISTANT_URL=http://homeassistant.local:8123
HOMEASSISTANT_TOKEN=
BROOMBOT_ENTITY_ID=vacuum.broombot
BROOMBOT_BATTERY_ENTITY_ID=sensor.broombot_battery
MOPBOT_ENTITY_ID=vacuum.mopbot
MOPBOT_BATTERY_ENTITY_ID=sensor.mopbot_battery

# Direct Robot Connection Configuration (Required if ROBOT_CONNECTION_TYPE=direct)
broombotModel=
broombotBlid=
broombotPassword=
broombotIp=
mopbotModel=
mopbotBlid=
mopbotPassword=
mopbotIp=

# Car Configuration (via Home Assistant Kia integration)
# Entity prefix is the name of your vehicle in Home Assistant (e.g., "kia_ev6")
CAR_ENTITY_PREFIX=kia

# Camera
CAMERA_URL=

# Miele Integration
mieleClientId=
mieleSecretId=
mieleAppliances=

# Bosch / Home Connect Integration
boschClientId=
boschSecretId=
boschAppliance=

# HomeKit Favorites
favouriteHomeKit=

# Modern Dog Integration
MODERN_DOG_URL=
MODERN_DOG_TOKEN=
MODERN_DOG_COOKIE=

# AI / Voice Configuration
# AI_PROVIDER: LLM backend for command processing.
#   Supported: anthropic (default), copilot/github-copilot, openai, zai/z.ai
#   Best for main model handling: copilot (GitHub Copilot) or anthropic (Claude)
AI_PROVIDER=anthropic
AI_MODEL=

# STT (Speech-to-Text): transcribes voice input before sending to LLM.
#   Supported: openai (default, uses OpenAI Whisper — best-in-class accuracy)
#   Best for V2T: openai (Whisper)
STT_PROVIDER=openai
STT_MODEL=whisper-1

# TTS (Text-to-Speech): synthesizes LLM response back to audio.
#   Supported: openai (default, uses OpenAI TTS — natural, low-latency)
#   Best for voice generation: openai (tts-1 / tts-1-hd) or elevenlabs (future)
TTS_PROVIDER=openai
TTS_MODEL=tts-1
# TTS_VOICE: alloy (default) | ash | coral | echo | fable | onyx | nova | sage | shimmer
TTS_VOICE=alloy
